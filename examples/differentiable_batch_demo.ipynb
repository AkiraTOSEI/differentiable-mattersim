{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 微分可能な MatterSim - バッチ処理のデモ\n",
    "\n",
    "このノートブックでは、MatterSim のバッチ処理機能を使って、複数の結晶を同時に処理し、入力（atom_types, lattice, positions）に対して勾配を計算する方法を示します。\n",
    "\n",
    "## 概要\n",
    "\n",
    "- **目的**: 複数の結晶を同時に処理し、バッチ最適化を行う\n",
    "- **新しい API**: `DifferentiableMatterSimCalculator.forward_batch()`\n",
    "- **主な機能**: \n",
    "  - 可変原子数のバッチ処理\n",
    "  - atom_types, lattice, positions への勾配計算\n",
    "  - Soft normalization による完全な勾配伝播"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Python 環境のセットアップと診断\nimport sys\nimport subprocess\nfrom pathlib import Path\n\n# 現在の環境情報\nprint(\"=\"*70)\nprint(\"Python 環境情報\")\nprint(\"=\"*70)\nprint(f\"Python executable: {sys.executable}\")\nprint(f\"Python version: {sys.version}\")\nprint(f\"Current directory: {Path.cwd()}\")\n\n# プロジェクトルートを特定\nproject_root = Path.cwd().parent\nsrc_path = project_root / \"src\"\nprint(f\"Project root: {project_root}\")\nprint(f\"Source path: {src_path}\")\n\n# mattersim のインストール状態を確認\nprint(\"\\n\" + \"=\"*70)\nprint(\"パッケージインストール状態\")\nprint(\"=\"*70)\n\ntry:\n    import mattersim\n    print(f\"✓ mattersim is installed\")\n    print(f\"  Location: {mattersim.__file__}\")\nexcept ImportError:\n    print(\"✗ mattersim is NOT installed\")\n\n# threebody_indices の確認\ntry:\n    from mattersim.datasets.utils import threebody_indices\n    print(f\"✓ threebody_indices module is available\")\nexcept ImportError as e:\n    print(f\"✗ threebody_indices module is NOT available: {e}\")\n    print(\"\\n\" + \"=\"*70)\n    print(\"解決策: 以下のいずれかを実行してください\")\n    print(\"=\"*70)\n    print(\"1. Jupyter カーネルを再起動してください（Kernel → Restart Kernel）\")\n    print(\"2. または、以下のセルのコメントを外して実行してください：\")\n    print(\"\")\n    print(\"# 次のセルで実行:\")\n    print(f\"# !cd {project_root} && pip install Cython && pip install -e .\")\n    raise\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"セットアップ完了\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 必要なライブラリのインポート\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ase.build import bulk\n\nfrom mattersim.forcefield.differentiable_potential import (\n    DifferentiableMatterSimCalculator,\n    sizes_to_batch_index,\n)\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ヘルパー関数の確認\n",
    "\n",
    "まず、バッチ処理に必要な `sizes_to_batch_index` 関数を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sizes から batch_index への変換\n",
    "sizes = torch.tensor([2, 3, 1])  # 3つの結晶: 2原子, 3原子, 1原子\n",
    "batch_index = sizes_to_batch_index(sizes)\n",
    "\n",
    "print(f\"sizes: {sizes}\")\n",
    "print(f\"batch_index: {batch_index}\")\n",
    "print(f\"\\n各原子がどの結晶に属するか: {batch_index.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. バッチ処理の基本\n",
    "\n",
    "Diamond Si と FCC-Fe の2つの結晶をバッチ処理します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2つの結晶を準備\n",
    "si = bulk(\"Si\", \"diamond\", a=5.43)\n",
    "fe = bulk(\"Fe\", \"fcc\", a=3.6)\n",
    "atoms_list = [si, fe]\n",
    "\n",
    "print(f\"Si: {len(si)} atoms\")\n",
    "print(f\"Fe: {len(fe)} atoms\")\n",
    "print(f\"Total: {len(si) + len(fe)} atoms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculator を初期化\n",
    "device = \"cpu\"  # または \"cuda\"\n",
    "calc = DifferentiableMatterSimCalculator(device=device)\n",
    "print(\"Calculator が初期化されました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチ入力を準備\n",
    "sizes = torch.tensor([len(si), len(fe)])\n",
    "\n",
    "# atom_types: concatenate\n",
    "atom_types_si = F.one_hot(torch.tensor(si.get_atomic_numbers()), 95).float()\n",
    "atom_types_fe = F.one_hot(torch.tensor(fe.get_atomic_numbers()), 95).float()\n",
    "atom_types = torch.cat([atom_types_si, atom_types_fe], dim=0)\n",
    "\n",
    "# positions: concatenate\n",
    "positions = torch.cat([\n",
    "    torch.tensor(si.get_positions(), dtype=torch.float32),\n",
    "    torch.tensor(fe.get_positions(), dtype=torch.float32)\n",
    "], dim=0)\n",
    "\n",
    "# lattice: stack\n",
    "lattice = torch.stack([\n",
    "    torch.tensor(si.cell.array, dtype=torch.float32),\n",
    "    torch.tensor(fe.cell.array, dtype=torch.float32)\n",
    "], dim=0)\n",
    "\n",
    "print(f\"atom_types shape: {atom_types.shape}  # (sum(N_i), 95)\")\n",
    "print(f\"positions shape:  {positions.shape}   # (sum(N_i), 3)\")\n",
    "print(f\"lattice shape:    {lattice.shape}     # (nb_graphs, 3, 3)\")\n",
    "print(f\"sizes:            {sizes}             # [N_1, N_2]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. バッチ forward の実行\n",
    "\n",
    "`forward_batch` メソッドで2つの結晶のエネルギーを同時に計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチ forward（勾配なし）\n",
    "output = calc.forward_batch(\n",
    "    atoms_list,\n",
    "    atom_types=atom_types,\n",
    "    positions=positions,\n",
    "    lattice=lattice,\n",
    "    sizes=sizes,\n",
    "    include_forces=False,\n",
    "    soft_normalize=False,  # まずは標準モード\n",
    ")\n",
    "\n",
    "energies = output[\"total_energy\"]\n",
    "print(f\"\\nバッチエネルギー:\")\n",
    "print(f\"  Si: {energies[0].item():.6f} eV\")\n",
    "print(f\"  Fe: {energies[1].item():.6f} eV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 勾配の計算\n",
    "\n",
    "atom_types, lattice, positions の3つすべてに対して勾配を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires_grad を設定\n",
    "atom_types_grad = atom_types.clone().requires_grad_(True)\n",
    "positions_grad = positions.clone().requires_grad_(True)\n",
    "lattice_grad = lattice.clone().requires_grad_(True)\n",
    "\n",
    "# Forward with soft_normalize=True（atom_types への勾配を維持）\n",
    "output = calc.forward_batch(\n",
    "    atoms_list,\n",
    "    atom_types=atom_types_grad,\n",
    "    positions=positions_grad,\n",
    "    lattice=lattice_grad,\n",
    "    sizes=sizes,\n",
    "    include_forces=False,\n",
    "    soft_normalize=True,\n",
    ")\n",
    "\n",
    "energies = output[\"total_energy\"]\n",
    "loss = energies.sum()\n",
    "\n",
    "# Backward\n",
    "loss.backward()\n",
    "\n",
    "# 勾配確認\n",
    "print(f\"\\n勾配計算結果:\")\n",
    "print(f\"  atom_types.grad is not None: {atom_types_grad.grad is not None}\")\n",
    "print(f\"  positions.grad is not None:  {positions_grad.grad is not None}\")\n",
    "print(f\"  lattice.grad is not None:    {lattice_grad.grad is not None}\")\n",
    "\n",
    "print(f\"\\n勾配ノルム:\")\n",
    "print(f\"  atom_types: {torch.norm(atom_types_grad.grad).item():.6e}\")\n",
    "print(f\"  positions:  {torch.norm(positions_grad.grad).item():.6e}\")\n",
    "print(f\"  lattice:    {torch.norm(lattice_grad.grad).item():.6e}\")\n",
    "\n",
    "print(\"\\n✓ 3変数すべてに勾配が計算されました！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. バッチ最適化のデモ\n",
    "\n",
    "2つの結晶の positions を同時に最適化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期位置に摂動を加える\n",
    "torch.manual_seed(42)\n",
    "positions_opt = positions.clone()\n",
    "positions_opt = positions_opt + torch.randn_like(positions_opt) * 0.02\n",
    "positions_opt.requires_grad_(True)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam([positions_opt], lr=0.02)\n",
    "\n",
    "# 最適化の履歴\n",
    "energy_history = []\n",
    "\n",
    "print(\"最適化を開始...\")\n",
    "num_steps = 30\n",
    "for step in range(num_steps):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = calc.forward_batch(\n",
    "        atoms_list,\n",
    "        positions=positions_opt,\n",
    "        sizes=sizes,\n",
    "        include_forces=False,\n",
    "    )\n",
    "    energies = output[\"total_energy\"]\n",
    "    loss = energies.sum()\n",
    "    \n",
    "    energy_history.append(energies.detach().cpu().numpy())\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 5 == 0:\n",
    "        print(f\"Step {step:2d}: Si = {energies[0].item():.6f} eV, Fe = {energies[1].item():.6f} eV\")\n",
    "\n",
    "print(f\"\\n最適化完了！\")\n",
    "print(f\"Si エネルギー変化: {energy_history[0][0]:.6f} → {energy_history[-1][0]:.6f} eV\")\n",
    "print(f\"Fe エネルギー変化: {energy_history[0][1]:.6f} → {energy_history[-1][1]:.6f} eV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. エネルギーの推移を可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_history = np.array(energy_history)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Si のエネルギー推移\n",
    "ax1.plot(energy_history[:, 0], 'b-', linewidth=2, label='Si')\n",
    "ax1.set_xlabel('最適化ステップ', fontsize=12)\n",
    "ax1.set_ylabel('エネルギー (eV)', fontsize=12)\n",
    "ax1.set_title('Diamond Si のエネルギー推移', fontsize=14)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Fe のエネルギー推移\n",
    "ax2.plot(energy_history[:, 1], 'r-', linewidth=2, label='Fe')\n",
    "ax2.set_xlabel('最適化ステップ', fontsize=12)\n",
    "ax2.set_ylabel('エネルギー (eV)', fontsize=12)\n",
    "ax2.set_title('FCC-Fe のエネルギー推移', fontsize=14)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ 2つの結晶が同時に最適化されました！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 連続分布 atom_types のデモ\n",
    "\n",
    "atom_types を one-hot ではなく、連続的な確率分布として扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits をパラメータ化\n",
    "torch.manual_seed(123)\n",
    "logits_si = torch.zeros(len(si), 95)\n",
    "logits_si[:, 14] = 5.0  # Si (原子番号14)\n",
    "logits_fe = torch.zeros(len(fe), 95)\n",
    "logits_fe[:, 26] = 5.0  # Fe (原子番号26)\n",
    "\n",
    "logits = torch.cat([logits_si, logits_fe], dim=0)\n",
    "logits += torch.randn_like(logits) * 0.5  # ノイズを加える\n",
    "logits.requires_grad_(True)\n",
    "\n",
    "print(\"初期 logits:\")\n",
    "print(f\"  Si[0, 13:16]: {logits[0, 13:16].detach()}\")\n",
    "print(f\"  Fe[2, 25:28]: {logits[2, 25:28].detach()}\")\n",
    "\n",
    "# Optimizer\n",
    "optimizer_logits = torch.optim.SGD([logits], lr=0.1)\n",
    "\n",
    "# 最適化\n",
    "for step in range(10):\n",
    "    optimizer_logits.zero_grad()\n",
    "    \n",
    "    atom_types_soft = F.softmax(logits, dim=1)\n",
    "    \n",
    "    output = calc.forward_batch(\n",
    "        atoms_list,\n",
    "        atom_types=atom_types_soft,\n",
    "        sizes=sizes,\n",
    "        include_forces=False,\n",
    "        soft_normalize=True,\n",
    "    )\n",
    "    \n",
    "    energies = output[\"total_energy\"]\n",
    "    \n",
    "    # 損失: エネルギー + regularization\n",
    "    atomic_numbers = torch.cat([\n",
    "        torch.tensor(si.get_atomic_numbers()),\n",
    "        torch.tensor(fe.get_atomic_numbers())\n",
    "    ], dim=0)\n",
    "    target = F.one_hot(atomic_numbers, num_classes=95).float()\n",
    "    loss = energies.sum() + 0.1 * F.mse_loss(atom_types_soft, target)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer_logits.step()\n",
    "\n",
    "print(\"\\n最終 logits:\")\n",
    "print(f\"  Si[0, 13:16]: {logits[0, 13:16].detach()}\")\n",
    "print(f\"  Fe[2, 25:28]: {logits[2, 25:28].detach()}\")\n",
    "\n",
    "atom_types_final = F.softmax(logits, dim=1)\n",
    "print(\"\\n最終 atom_types (確率分布):\")\n",
    "print(f\"  Si[0, 13:16]: {atom_types_final[0, 13:16].detach()}\")\n",
    "print(f\"  Fe[2, 25:28]: {atom_types_final[2, 25:28].detach()}\")\n",
    "\n",
    "print(\"\\n✓ 連続分布の atom_types で勾配更新が動作しました！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. まとめ\n",
    "\n",
    "このノートブックでは、以下を実演しました：\n",
    "\n",
    "1. ✅ **ヘルパー関数**: `sizes_to_batch_index` による batch_index 生成\n",
    "2. ✅ **バッチ forward**: 複数結晶の同時エネルギー計算\n",
    "3. ✅ **3変数の勾配**: atom_types, lattice, positions すべてに勾配計算\n",
    "4. ✅ **バッチ最適化**: 2つの結晶を同時に最適化\n",
    "5. ✅ **可視化**: エネルギー推移のプロット\n",
    "6. ✅ **連続分布 atom_types**: 非one-hot での勾配更新\n",
    "\n",
    "### 主なポイント\n",
    "\n",
    "- `forward_batch()` を使用してバッチ処理\n",
    "- `soft_normalize=True` で atom_types への完全な勾配伝播\n",
    "- `sizes` または `batch_index` で可変原子数に対応\n",
    "- PyTorch の optimizer で入力を更新\n",
    "\n",
    "### 次のステップ\n",
    "\n",
    "- より複雑な損失関数を定義（例: 目標構造との距離）\n",
    "- 3つ以上の結晶のバッチ処理\n",
    "- lattice の制約付き最適化（正定値性の維持など）\n",
    "\n",
    "詳細なドキュメントは `docs/DIFFERENTIABLE_API.md` を参照してください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}